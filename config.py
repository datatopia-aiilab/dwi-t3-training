"""
Configuration file for DWI Ischemic Stroke Segmentation Project
Contains all hyperparameters, paths, and settings
"""

import os
from pathlib import Path

# ==================== Project Paths ====================
PROJECT_ROOT = Path(__file__).parent
DATA_RAW = PROJECT_ROOT / "1_data_raw"
DATA_PROCESSED = PROJECT_ROOT / "2_data_processed"
MODEL_WEIGHTS = PROJECT_ROOT / "3_model_weights"
RESULTS_DIR = PROJECT_ROOT / "4_results"

# Raw data subdirectories
RAW_IMAGES_DIR = DATA_RAW / "images"
RAW_MASKS_DIR = DATA_RAW / "masks"

# Processed data subdirectories
PROCESSED_TRAIN_IMG = DATA_PROCESSED / "train" / "images"
PROCESSED_TRAIN_MASK = DATA_PROCESSED / "train" / "masks"
PROCESSED_VAL_IMG = DATA_PROCESSED / "val" / "images"
PROCESSED_VAL_MASK = DATA_PROCESSED / "val" / "masks"
PROCESSED_TEST_IMG = DATA_PROCESSED / "test" / "images"
PROCESSED_TEST_MASK = DATA_PROCESSED / "test" / "masks"

# Results subdirectories
PLOTS_DIR = RESULTS_DIR / "plots"
PREDICTIONS_DIR = RESULTS_DIR / "predictions"

# ==================== Data Parameters ====================
# Image specifications
IMAGE_SIZE = (384, 384)  # (Height, Width) - ‡∏à‡∏∞ resize ‡∏ó‡∏∏‡∏Å‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡∏ô‡∏µ‡πâ
ORIGINAL_SIZE = None  # ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

# Data split ratio
# Test: ‡∏ï‡∏≤‡∏¢‡∏ï‡∏±‡∏ß 48 slices (~5.66%)
# ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 800: Train 80% (640) + Val 20% (160)
TRAIN_RATIO = 0.80  # 80% ‡∏Ç‡∏≠‡∏á (total - test) = 640 slices
VAL_RATIO = 0.20    # 20% ‡∏Ç‡∏≠‡∏á (total - test) = 160 slices  
TEST_RATIO = 0.06 # ‡∏ï‡∏≤‡∏¢‡∏ï‡∏±‡∏ß 48 slices (~5.66% ‡∏Ç‡∏≠‡∏á total)

# Random seed for reproducibility
RANDOM_SEED = 10

# Minimum slices per patient (for filtering)
MIN_SLICES_PER_PATIENT = 1  # ‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏õ‡πá‡∏ô 1 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å patient (‡πÉ‡∏ä‡πâ zero padding)

# File naming pattern
# Format: Patient_{XXX}_Slice_{YYY}.{extension}
PATIENT_PATTERN = r'Patient_(\d+)_Slice_(\d+)'  # Regex pattern for parsing filenames

# ==================== Preprocessing Parameters ====================
# CLAHE (Contrast Limited Adaptive Histogram Equalization)
CLAHE_ENABLED = False  # ‚¨áÔ∏è ‡∏õ‡∏¥‡∏î CLAHE ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ú‡∏•‡πÅ‡∏¢‡πà‡∏•‡∏á (55% vs 72%)
CLAHE_CLIP_LIMIT = 0.03  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏° contrast (‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥ = ‡∏≠‡πà‡∏≠‡∏ô‡πÇ‡∏¢‡∏ô, ‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á = ‡πÅ‡∏£‡∏á)
CLAHE_KERNEL_SIZE = None  # None = auto-calculate based on image size

# Normalization
NORMALIZE_METHOD = 'zscore'  # 'zscore', 'minmax', or 'none'
# Z-score parameters (‡∏à‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≤‡∏Å training set)
TRAIN_MEAN = None  # ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô preprocessing
TRAIN_STD = None   # ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô preprocessing

# ==================== Model Architecture Parameters ====================
# Input
IN_CHANNELS = 3  # 2.5D input: [N-1, N, N+1] slices

# Output
OUT_CHANNELS = 1  # Binary segmentation (background vs lesion)

# ==================== Architecture Selection ====================
# Available architectures:
#   'attention_unet' - Custom Attention U-Net (current baseline, 17.5M params)
#   'unet++'         - U-Net++ with nested skip connections (~20M params)
#   'fpn'            - Feature Pyramid Network (~25M params)
#   'deeplabv3+'     - DeepLabV3+ with ASPP (~40M params)
#   'manet'          - Multi-Attention Network (~22M params)
#   'pspnet'         - Pyramid Scene Parsing Network (~45M params)

MODEL_ARCHITECTURE = 'unet++'  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ architecture ‡∏≠‡∏∑‡πà‡∏ô

# ==================== Encoder Selection (for SMP models) ====================
# Available encoders (when using unet++, fpn, deeplabv3+, manet, pspnet):
#   'resnet34'       - ResNet-34 (~21M params, balanced)
#   'resnet50'       - ResNet-50 (~25M params, more capacity)
#   'efficientnet-b0' - EfficientNet-B0 (~5M params, efficient)
#   'efficientnet-b3' - EfficientNet-B3 (~12M params, powerful)
#   'resnext50_32x4d' - ResNeXt-50 (~25M params, strong)
#   'timm-efficientnet-b5' - EfficientNet-B5 from timm (~30M params)

ENCODER_NAME = 'efficientnet-b0'  # Default encoder for SMP models

# Pre-trained weights
ENCODER_WEIGHTS = 'imagenet'  # Options: 'imagenet' (pre-trained), None (random init)

# ==================== Custom U-Net Architecture (for attention_unet only) ====================
# Round 3 (Baseline): [64,128,256,512] ‚Üí 31M ‚Üí Val 72%, Test 56%, Gap 16%
# Round 6 (Small): [32,64,128,256] ‚Üí 7.8M ‚Üí Val 61% (underfitting)
# Round 7 (Medium, no aug): [48,96,192,384] ‚Üí 17.5M ‚Üí Val 67%, Test 53%
# Round 8 (Medium + light aug): [48,96,192,384] ‚Üí Val 69%, Test 53% ‚≠ê Best balance
# Round 9 (Large + heavy reg): [64,128,256,512] ‚Üí Val 64%, Test 55% (underfitting)
# Round 10 (Medium + optimized): [48,96,192,384] ‚Üí Val 70%, Test 62% ‚≠ê **BEST**
ENCODER_CHANNELS = [48, 96, 192, 384]  # For attention_unet only
DECODER_CHANNELS = [384, 192, 96, 48]  # For attention_unet only
BOTTLENECK_CHANNELS = 768  # For attention_unet only

# Attention Gate
USE_ATTENTION = True  # ‡πÄ‡∏õ‡∏¥‡∏î/‡∏õ‡∏¥‡∏î Attention Gates (for attention_unet only)

# ==================== Training Parameters ====================
# Basic training settings
NUM_EPOCHS = 200  # ‚¨áÔ∏è ‡∏•‡∏î‡∏•‡∏á‡∏à‡∏≤‡∏Å 250 (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ train ‡∏ô‡∏≤‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ)
BATCH_SIZE = 4  # ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏° GPU memory (‡∏ñ‡πâ‡∏≤ out of memory ‡πÉ‡∏´‡πâ‡∏•‡∏î‡∏•‡∏á)
NUM_WORKERS = 4  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô workers ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DataLoader

# Optimizer
OPTIMIZER = 'adamw'  # 'adam' or 'adamw'
LEARNING_RATE = 8e-5  # ‚¨ÜÔ∏è‚¨ÜÔ∏è ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏µ‡∏Å (‡∏à‡∏≤‡∏Å 3e-5) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
WEIGHT_DECAY = 8e-5  # ‚¨áÔ∏è ‡∏•‡∏î‡∏•‡∏á (‡∏à‡∏≤‡∏Å 2e-4) ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á 1e-5 ‡∏Å‡∏±‡∏ö 1e-4

# Gradient clipping (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô exploding gradients)
GRADIENT_CLIP_VALUE = 1.0  # Clip gradients ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 1.0

# Learning rate scheduler
SCHEDULER = 'cosine'  # 'reduce_on_plateau' or 'cosine'
SCHEDULER_PATIENCE = 12  # ‚¨ÜÔ∏è ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏µ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô)
SCHEDULER_FACTOR = 0.5  # ‡∏•‡∏î LR ‡πÄ‡∏õ‡πá‡∏ô 0.5 ‡πÄ‡∏ó‡πà‡∏≤
SCHEDULER_MIN_LR = 1e-7  # LR ‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î

# Loss function  
LOSS_TYPE = 'dice'  # ‚¨áÔ∏è ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÉ‡∏ä‡πâ Dice (Combo ‡∏ó‡∏≥ NaN ‡πÅ‡∏°‡πâ LR ‡∏ï‡πà‡∏≥ + Gamma 1.5)
FOCAL_ALPHA = 0.25  # Weight for positive class in Focal Loss
FOCAL_GAMMA = 2.0   # Focusing parameter
DICE_SMOOTH = 1e-6  # Smoothing factor for Dice Loss
COMBO_FOCAL_WEIGHT = 0.3  # ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å Focal Loss
COMBO_DICE_WEIGHT = 0.7   # ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å Dice Loss


# Early stopping
EARLY_STOPPING_PATIENCE = 100  # ‚¨áÔ∏è ‡∏•‡∏î‡∏•‡∏á‡∏à‡∏≤‡∏Å 40 (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠‡∏ô‡∏≤‡∏ô)
EARLY_STOPPING_MIN_DELTA = 1e-4  # ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏ó‡∏µ‡πà‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤ "‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô"

# Checkpointing
SAVE_BEST_ONLY = True  # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
CHECKPOINT_METRIC = 'val_dice'  # Metric ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à
CHECKPOINT_MODE = 'max'  # 'max' (‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤ = ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤) or 'min' (‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ = ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤)

# ==================== Data Augmentation Parameters ====================
AUGMENTATION_ENABLED = True  # ‚¨ÜÔ∏è ‡∏Ñ‡∏á‡πÑ‡∏ß‡πâ (Round 8 ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏î‡∏µ)

# Augmentation - ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ Round 8 ‡∏ó‡∏µ‡πà balanced ‡∏î‡∏µ
AUG_HORIZONTAL_FLIP_PROB = 0.3  # ‚¨áÔ∏è ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô 0.3 (Round 8)
AUG_VERTICAL_FLIP_PROB = 0.0  # ‡πÑ‡∏°‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö medical images
AUG_ROTATE_PROB = 0.25  # ‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ (‡∏à‡∏≤‡∏Å 0.3)
AUG_ROTATE_LIMIT = 10  # ‡∏Ñ‡∏á ¬±10¬∞

AUG_ELASTIC_TRANSFORM_PROB = 0.15  # ‚¨áÔ∏è ‡∏•‡∏î‡∏•‡∏á (‡∏à‡∏≤‡∏Å 0.2) ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ
AUG_ELASTIC_ALPHA = 0.5  # ‡∏Ñ‡∏á 0.5 (‡∏≠‡πà‡∏≠‡∏ô)
AUG_ELASTIC_SIGMA = 50.0

AUG_BRIGHTNESS_CONTRAST_PROB = 0.2  # ‡∏Ñ‡∏á 0.2
AUG_BRIGHTNESS_LIMIT = 0.08  # ‡∏Ñ‡∏á 0.08
AUG_CONTRAST_LIMIT = 0.08  # ‡∏Ñ‡∏á 0.08

AUG_GAUSSIAN_NOISE_PROB = 0.12  # ‚¨áÔ∏è ‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ (‡∏à‡∏≤‡∏Å 0.15)
AUG_GAUSSIAN_NOISE_VAR = (5.0, 22.0)  # ‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ (‡∏à‡∏≤‡∏Å 25)

# ==================== Evaluation Parameters ====================
# Metrics
EVAL_METRICS = ['dice', 'iou', 'precision', 'recall', 'f1']

# Visualization
NUM_QUALITATIVE_SAMPLES = 10  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô evaluation
VIZ_ALPHA = 0.5  # ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÇ‡∏õ‡∏£‡πà‡∏á‡πÉ‡∏™‡∏Ç‡∏≠‡∏á mask overlay (0.0-1.0)
VIZ_GT_COLOR = (1.0, 0.0, 0.0)  # ‡∏™‡∏µ‡πÅ‡∏î‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Ground Truth
VIZ_PRED_COLOR = (0.0, 1.0, 1.0)  # ‡∏™‡∏µ‡∏ü‡πâ‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Prediction

# Threshold for binary mask
PREDICTION_THRESHOLD = 0.5  # Threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á probability ‡πÄ‡∏õ‡πá‡∏ô binary mask

# ==================== Hardware Settings ====================
import torch

# Device configuration
USE_CUDA = torch.cuda.is_available()
DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')
NUM_GPUS = torch.cuda.device_count() if USE_CUDA else 0

# Mixed precision training (faster training on modern GPUs)
USE_MIXED_PRECISION = True if USE_CUDA else False

# ==================== Logging Settings ====================
LOG_INTERVAL = 10  # ‡∏û‡∏¥‡∏°‡∏û‡πå progress ‡∏ó‡∏∏‡∏Å‡πÜ N batches
SAVE_LOG_FILE = True
LOG_FILE = RESULTS_DIR / "training_log.txt"

# Tensorboard
USE_TENSORBOARD = False  # ‡πÄ‡∏õ‡∏¥‡∏î/‡∏õ‡∏¥‡∏î Tensorboard logging
TENSORBOARD_DIR = RESULTS_DIR / "tensorboard"

# ==================== MLflow Settings ====================
# MLflow - Experiment Tracking & Model Registry
MLFLOW_ENABLED = True  # ‡πÄ‡∏õ‡∏¥‡∏î/‡∏õ‡∏¥‡∏î MLflow tracking
MLFLOW_TRACKING_URI = str(PROJECT_ROOT / "mlruns")  # Local tracking directory
MLFLOW_EXPERIMENT_NAME = f"DWI-NOV-{MODEL_ARCHITECTURE}"  # ‡∏ä‡∏∑‡πà‡∏≠ experiment
MLFLOW_RUN_NAME = None  # None = auto-generate (e.g., "unet++_resnet34_20250108_143022")

# MLflow Tags (‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô run automatically)
# - architecture: MODEL_ARCHITECTURE
# - encoder: ENCODER_NAME (for SMP models)
# - pretrained: "yes" / "no"
# - augmentation: "enabled" / "disabled"
# - loss_type: LOSS_TYPE

# ==================== Helper Functions ====================
def create_directories():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á directories ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"""
    dirs = [
        DATA_RAW, DATA_PROCESSED, MODEL_WEIGHTS, RESULTS_DIR,
        RAW_IMAGES_DIR, RAW_MASKS_DIR,
        PROCESSED_TRAIN_IMG, PROCESSED_TRAIN_MASK,
        PROCESSED_VAL_IMG, PROCESSED_VAL_MASK,
        PROCESSED_TEST_IMG, PROCESSED_TEST_MASK,
        PLOTS_DIR, PREDICTIONS_DIR
    ]
    
    if USE_TENSORBOARD:
        dirs.append(TENSORBOARD_DIR)
    
    for directory in dirs:
        directory.mkdir(parents=True, exist_ok=True)
    
    print("‚úÖ Created all necessary directories")


def print_config():
    """‡∏û‡∏¥‡∏°‡∏û‡πå configuration ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÜ"""
    print("\n" + "="*60)
    print("üîß DWI ISCHEMIC STROKE SEGMENTATION - CONFIGURATION")
    print("="*60)
    print(f"\nüìÅ Paths:")
    print(f"   Project Root: {PROJECT_ROOT}")
    print(f"   Raw Data: {DATA_RAW}")
    print(f"   Processed Data: {DATA_PROCESSED}")
    print(f"   Model Weights: {MODEL_WEIGHTS}")
    print(f"   Results: {RESULTS_DIR}")
    
    print(f"\nüìä Data:")
    print(f"   Image Size: {IMAGE_SIZE}")
    print(f"   Train/Val/Test Split: {TRAIN_RATIO}/{VAL_RATIO}/{TEST_RATIO}")
    print(f"   Min Slices per Patient: {MIN_SLICES_PER_PATIENT}")
    
    print(f"\nüî¨ Preprocessing:")
    print(f"   CLAHE Enabled: {CLAHE_ENABLED}")
    print(f"   CLAHE Clip Limit: {CLAHE_CLIP_LIMIT}")
    print(f"   Normalization: {NORMALIZE_METHOD}")
    
    print(f"\nüèóÔ∏è Model:")
    print(f"   Architecture: {MODEL_ARCHITECTURE.upper()}")
    print(f"   Input Channels: {IN_CHANNELS}")
    print(f"   Output Channels: {OUT_CHANNELS}")
    
    if MODEL_ARCHITECTURE == 'attention_unet':
        print(f"   Encoder Channels: {ENCODER_CHANNELS}")
        print(f"   Bottleneck: {BOTTLENECK_CHANNELS}")
        print(f"   Use Attention: {USE_ATTENTION}")
    else:
        print(f"   Encoder: {ENCODER_NAME}")
        print(f"   Pre-trained: {ENCODER_WEIGHTS or 'None (random init)'}")
    
    print(f"\nüéì Training:")
    print(f"   Epochs: {NUM_EPOCHS}")
    print(f"   Batch Size: {BATCH_SIZE}")
    print(f"   Learning Rate: {LEARNING_RATE}")
    print(f"   Optimizer: {OPTIMIZER.upper()}")
    print(f"   Loss: {LOSS_TYPE.upper()}")
    if LOSS_TYPE == 'combo':
        print(f"      Focal Weight: {COMBO_FOCAL_WEIGHT}, Dice Weight: {COMBO_DICE_WEIGHT}")
    print(f"   Scheduler: {SCHEDULER}")
    print(f"   Early Stopping Patience: {EARLY_STOPPING_PATIENCE}")
    
    print(f"\nüñºÔ∏è Augmentation:")
    print(f"   Enabled: {AUGMENTATION_ENABLED}")
    if AUGMENTATION_ENABLED:
        print(f"   Horizontal Flip: {AUG_HORIZONTAL_FLIP_PROB}")
        print(f"   Rotation: {AUG_ROTATE_PROB} (¬±{AUG_ROTATE_LIMIT}¬∞)")
        print(f"   Elastic Transform: {AUG_ELASTIC_TRANSFORM_PROB}")
        print(f"   Brightness/Contrast: {AUG_BRIGHTNESS_CONTRAST_PROB}")
    
    print(f"\nüíª Hardware:")
    print(f"   Device: {DEVICE}")
    if USE_CUDA:
        print(f"   GPU(s): {NUM_GPUS} x {torch.cuda.get_device_name(0)}")
        print(f"   Mixed Precision: {USE_MIXED_PRECISION}")
    
    print("\n" + "="*60 + "\n")


def get_model_save_path(name='best_model'):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    return MODEL_WEIGHTS / f"{name}.pth"


def get_checkpoint_path(epoch):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö checkpoint ‡πÅ‡∏ï‡πà‡∏•‡∏∞ epoch"""
    return MODEL_WEIGHTS / f"checkpoint_epoch_{epoch:03d}.pth"


if __name__ == "__main__":
    # Test configuration
    print_config()
    create_directories()
    print("‚úÖ Configuration loaded successfully!")
