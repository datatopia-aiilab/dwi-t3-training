# DWI Baseline Training - Simple & Clean

‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DWI Ischemic Stroke Segmentation
**‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢ ‡πÑ‡∏°‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô!**

---

## üìÅ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á

```
t3-training-base/
‚îú‚îÄ‚îÄ config.py          # ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
‚îú‚îÄ‚îÄ model.py           # Attention U-Net (simple)
‚îú‚îÄ‚îÄ train.py           # All-in-one: preprocess + train + evaluate
‚îú‚îÄ‚îÄ README.md          # ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏ô‡∏µ‡πâ
‚îÇ
‚îú‚îÄ‚îÄ models/            # (auto-created) - temporary storage
‚îÇ   ‚îî‚îÄ‚îÄ best_model.pth
‚îÇ
‚îî‚îÄ‚îÄ mlruns/            # (auto-created) - MLflow tracking
    ‚îî‚îÄ‚îÄ 0/
        ‚îî‚îÄ‚îÄ <run_id>/
            ‚îú‚îÄ‚îÄ params/
            ‚îú‚îÄ‚îÄ metrics/
            ‚îî‚îÄ‚îÄ artifacts/
                ‚îú‚îÄ‚îÄ training_curve.png
                ‚îú‚îÄ‚îÄ test_predictions/
                ‚îú‚îÄ‚îÄ best_model.pth
                ‚îî‚îÄ‚îÄ test_metrics.json
```

---

## üöÄ ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Environment

```bash
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ)
pip install torch torchvision
pip install nibabel opencv-python albumentations
pip install matplotlib tqdm
pip install mlflow
```

### 2. ‡∏£‡∏±‡∏ô Training (‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß!)

```bash
cd t3-training-base

# (‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å) ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô
python check_data.py

# ‡∏£‡∏±‡∏ô training
python train.py
```

**‡∏à‡∏∞‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á:**
1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å `../1_data_raw/` (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á .npy ‡πÅ‡∏•‡∏∞ .nii.gz)
2. Preprocess ‡πÉ‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ (resize, normalize, 2.5D)
3. ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• train/val/test (80/15/5)
4. Train Attention U-Net (100 epochs ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏ô early stop)
5. Evaluate ‡∏ö‡∏ô test set
6. Log ‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á MLflow
7. ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!

### 3. ‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå

```bash
# ‡πÄ‡∏õ‡∏¥‡∏î MLflow UI
mlflow ui --port 5000

# ‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå
http://localhost:5000
```

---

## üìä ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà MLflow ‡∏à‡∏∞‡πÄ‡∏Å‡πá‡∏ö

### Parameters:
- `image_size`: (384, 384)
- `batch_size`: 16
- `learning_rate`: 0.0001
- `epochs`: 100
- `base_channels`: 64
- `model_params`: ~31M
- ‡πÅ‡∏•‡∏∞‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

### Metrics (‡∏ó‡∏∏‡∏Å epoch):
- `train_loss`
- `train_dice`
- `val_loss`
- `val_dice`
- `learning_rate`

### Test Metrics:
- `test_dice_mean`
- `test_dice_std`
- `test_iou_mean`
- `test_iou_std`

### Artifacts:
- `training_curve.png` - ‡∏Å‡∏£‡∏≤‡∏ü loss + dice
- `test_predictions/` - 10 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (GT vs Pred)
- `best_model.pth` - ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
- `test_metrics.json` - ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô

---

## ‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤

‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏ô `config.py`:

```python
# Data
IMAGE_SIZE = (384, 384)
TRAIN_RATIO = 0.80
VAL_RATIO = 0.15
TEST_RATIO = 0.05

# Model
BASE_CHANNELS = 64  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡πâ‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô ‚Üí ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô

# Training
EPOCHS = 100
BATCH_SIZE = 16
LEARNING_RATE = 1e-4
EARLY_STOP_PATIENCE = 20

# Augmentation
AUG_HFLIP_PROB = 0.3
AUG_ROTATE_PROB = 0.25
AUG_BRIGHTNESS_PROB = 0.2
```

---

## üéØ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á

**Baseline Performance (‡πÑ‡∏°‡πà‡∏°‡∏µ optimization):**
- Val Dice: **60-70%**
- Test Dice: **55-65%**
- Training Time: ~90-120 minutes (100 epochs, RTX 3080)
- Convergence: ~40-60 epochs

**‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡πÄ‡∏Å‡πà‡∏≤?**
- ‡πÑ‡∏°‡πà‡∏°‡∏µ N4 bias correction
- ‡πÑ‡∏°‡πà‡∏°‡∏µ Deep Supervision
- ‡πÑ‡∏°‡πà‡∏°‡∏µ TTA/CCA
- ‡πÅ‡∏ï‡πà‡∏à‡∏∞ **stable, simple, debugable**!

---

## üèóÔ∏è Model Architecture

**Attention U-Net:**

```
Encoder:
  Conv Block 1: 3 ‚Üí 64
  Conv Block 2: 64 ‚Üí 128
  Conv Block 3: 128 ‚Üí 256
  Conv Block 4: 256 ‚Üí 512

Bottleneck:
  Conv Block 5: 512 ‚Üí 1024

Decoder (with Attention Gates):
  Up Block 1: 1024 ‚Üí 512 + Attention
  Up Block 2: 512 ‚Üí 256 + Attention
  Up Block 3: 256 ‚Üí 128 + Attention
  Up Block 4: 128 ‚Üí 64 + Attention

Output:
  Conv: 64 ‚Üí 1 (Sigmoid)

Total Parameters: ~31M
```

**‡πÑ‡∏°‡πà‡∏°‡∏µ:**
- Deep Supervision
- SE/CBAM/ECA modules
- Multi-scale features
- ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡πÜ

**‡∏°‡∏µ‡πÅ‡∏Ñ‡πà:**
- Standard U-Net structure
- Attention Gates (spatial attention)
- BatchNorm + ReLU
- ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô!

---

## üìù ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏

### ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:
‚úÖ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢ ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢
‚úÖ ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ó‡∏≥‡∏Ñ‡∏£‡∏ö
‚úÖ Debug ‡∏á‡πà‡∏≤‡∏¢ (‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏±‡πâ‡∏ô)
‚úÖ ‡πÄ‡∏Å‡πá‡∏ö‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô MLflow
‚úÖ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏£‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢
‚úÖ Reproducible

### ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î:
‚ùå Performance ‡πÑ‡∏°‡πà‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (‡πÄ‡∏õ‡πá‡∏ô baseline)
‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ advanced features
‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ N4, Deep Supervision, TTA

### ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ:
- ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ baseline ‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡πÑ‡∏î‡πâ
- ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö idea ‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß
- ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ debug ‡∏á‡πà‡∏≤‡∏¢
- ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô

---

## üîß Troubleshooting

### ‡∏ñ‡πâ‡∏≤ Out of Memory:
```python
# ‡πÉ‡∏ô config.py
BATCH_SIZE = 8  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 16
```

### ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏•‡πá‡∏Å‡∏•‡∏á:
```python
# ‡πÉ‡∏ô config.py
BASE_CHANNELS = 32  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 64
# Parameters ‡∏à‡∏∞‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠ ~8M
```

### ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ train ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô:
```python
# ‡πÉ‡∏ô config.py
EPOCHS = 50  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 100
EARLY_STOP_PATIENCE = 10  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 20
```

---

## üìö ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ï‡πà‡∏≠

‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ó‡∏µ‡∏•‡∏∞‡∏≠‡∏¢‡πà‡∏≤‡∏á:

1. **N4 Bias Correction** (+3-5% Dice)
2. **Deep Supervision** (+2-4% Dice)
3. **TTA + CCA** (+2-4% Dice)
4. **‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Loss Function** (+1-2% Dice)

‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô run ‡πÅ‡∏¢‡∏Å‡πÉ‡∏ô MLflow ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö!

---

## üéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß!

‡∏£‡∏±‡∏ô `python train.py` ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏≠‡∏ú‡∏•‡∏Ñ‡∏£‡∏±‡∏ö! üöÄ

‡∏î‡∏π‡∏ú‡∏•‡πÉ‡∏ô MLflow UI: `mlflow ui --port 5000`
