# üöÄ Quick Start Guide: Model Improvements
## ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà

**‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï:** 27 ‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô 2568

---

## ‚úÖ **‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô**

### ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß (Phase 1-2):
- ‚úÖ Test-Time Augmentation (TTA)
- ‚úÖ Connected Component Analysis (CCA)
- ‚úÖ N4 Bias Field Correction

### ‡∏£‡∏≠‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£ (Phase 3-4):
- üîÑ Gamma Correction Augmentation
- üîÑ Log-Cosh Dice Loss
- üîÑ Deep Supervision

---

## üì¶ **‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: Install Dependencies**

```bash
# Navigate to project directory
cd /Users/Sribilone/AiiLAB/_datatopia/DWI/NovEdition/dwi-t3-training

# Install/update requirements
pip install -r requirements.txt

# ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ SimpleITK ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
python -c "import SimpleITK as sitk; print(f'SimpleITK version: {sitk.Version.VersionString()}')"
```

---

## üß™ **‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö TTA + CCA (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á Retrain)**

### 2.1 ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Configuration

```bash
# ‡∏î‡∏π config ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
python -c "
import config
print('='*60)
print('TTA + CCA Configuration')
print('='*60)
print(f'USE_TTA: {config.USE_TTA}')
print(f'TTA_AUGMENTATIONS: {config.TTA_AUGMENTATIONS}')
print(f'USE_CCA: {config.USE_CCA}')
print(f'CCA_MIN_SIZE: {config.CCA_MIN_SIZE} pixels')
print(f'CCA_MIN_CONFIDENCE: {config.CCA_MIN_CONFIDENCE}')
print('='*60)
"
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÄ‡∏´‡πá‡∏ô:**
```
============================================================
TTA + CCA Configuration
============================================================
USE_TTA: True
TTA_AUGMENTATIONS: ['hflip', 'vflip']
USE_CCA: True
CCA_MIN_SIZE: 10 pixels
CCA_MIN_CONFIDENCE: 0.3
============================================================
```

### 2.2 Run Evaluation ‡∏Å‡∏±‡∏ö Model ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô

```bash
# Evaluate with TTA + CCA (‡πÉ‡∏ä‡πâ best_model.pth ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà)
python evaluate.py --num_samples 48

# ‡∏´‡∏£‡∏∑‡∏≠ evaluate ‡∏ó‡∏∏‡∏Å test samples
python evaluate.py --num_samples 999
```

**‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô:**
- ‡πÇ‡∏´‡∏•‡∏î `best_model.pth`
- ‡πÉ‡∏ä‡πâ TTA ‡∏ó‡∏≥ prediction ‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á (hflip, vflip)
- Average predictions
- Apply CCA cleaning
- ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Output:**
```
üöÄ Running evaluation with TTA+CCA...
üîÑ TTA enabled with: ['hflip', 'vflip']
   Number of predictions to average: 3
‚úÖ CCA enabled: min_size=10px, min_conf=0.3

Evaluating (TTA+CCA): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [01:23<00:00]

üìä TEST SET RESULTS (with TTA+CCA):
   Dice:      0.6523 ¬± 0.1234  (+0.0323 vs baseline)
   IoU:       0.5234 ¬± 0.1123
   Precision: 0.7123 ¬± 0.1345  (+0.0523 vs baseline)
   Recall:    0.6234 ¬± 0.1256
```

### 2.3 ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå

```bash
# ‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
cat 4_results/test_per_sample_results.csv

# ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ Python
python -c "
import pandas as pd
df = pd.read_csv('4_results/test_per_sample_results.csv')
print(df[['filename', 'dice', 'precision', 'recall']].head(10))
print(f'\nAverage Dice: {df['dice'].mean():.4f}')
print(f'Average Precision: {df['precision'].mean():.4f}')
"
```

### 2.4 ‡∏õ‡∏¥‡∏î TTA/CCA ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö (Optional)

```python
# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç config.py
USE_TTA = False
USE_CCA = False

# Run evaluate ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
python evaluate.py
```

---

## üî¨ **‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: Re-preprocess ‡∏î‡πâ‡∏ß‡∏¢ N4 Correction**

### 3.1 Backup ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°

```bash
# Backup processed data
mv 2_data_processed 2_data_processed_backup

# ‡∏´‡∏£‡∏∑‡∏≠ copy (‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Å‡∏ß‡πà‡∏≤ ‡πÅ‡∏ï‡πà‡πÉ‡∏ä‡πâ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤)
cp -r 2_data_processed 2_data_processed_backup
```

### 3.2 ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö N4 Configuration

```bash
python -c "
import config
print('='*60)
print('N4 Bias Correction Configuration')
print('='*60)
print(f'N4_ENABLED: {config.N4_ENABLED}')
print(f'N4_SHRINK_FACTOR: {config.N4_SHRINK_FACTOR}')
print(f'N4_NUM_ITERATIONS: {config.N4_NUM_ITERATIONS}')
print(f'N4_NUM_WORKERS: {config.N4_NUM_WORKERS}')
print('='*60)
print('\nEstimated processing time:')
print('  Single-threaded: ~2-4 hours')
print(f'  {config.N4_NUM_WORKERS} workers: ~30-60 minutes')
print('='*60)
"
```

### 3.3 Run Preprocessing

```bash
# Run preprocessing with N4 correction
# ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 30-60 ‡∏ô‡∏≤‡∏ó‡∏µ (4 workers)
python 01_preprocess.py
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á:**
```
============================================================
PREPROCESSING DWI IMAGES
============================================================

Step 1: Creating directories...
‚úÖ Created all necessary directories

Step 2: Building slice mappings...
Found 848 image-mask pairs
Train: 640 slices
Val: 160 slices
Test: 48 slices

Step 3: Computing normalization stats from training set...
Loading images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 640/640
Mean: 156.2341
Std:  89.1234

Step 4: Processing splits...
üöÄ Processing train set (640 files)...
   N4 correction enabled (shrink=4, workers=4)
   train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 640/640 [25:32<00:00, 0.42it/s]
   ‚úÖ TRAIN: 640/640 files processed successfully

üöÄ Processing val set (160 files)...
   val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [06:23<00:00, 0.42it/s]
   ‚úÖ VAL: 160/160 files processed successfully

üöÄ Processing test set (48 files)...
   test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [01:55<00:00, 0.42it/s]
   ‚úÖ TEST: 48/48 files processed successfully

Step 5: Saving preprocessing config...
‚úÖ Saved to: 2_data_processed/preprocess_config.json

============================================================
‚úÖ PREPROCESSING COMPLETED!
============================================================
Total time: 33 minutes 50 seconds
```

### 3.4 ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå

```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö config ‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
cat 2_data_processed/preprocess_config.json

# ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏´‡πá‡∏ô:
# "n4_enabled": true,
# "n4_shrink_factor": 4,
# "n4_num_iterations": 50,
```

---

## üéì **‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: Retrain Model**

### 4.1 Run Training

```bash
# Train model ‡∏î‡πâ‡∏ß‡∏¢ N4-corrected data
python train.py

# Expected training time: 6-12 hours (depends on GPU)
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á:**
```
Epoch 50/100 - 145.2s - LR: 0.000042
  Train Loss: 0.2234 | Train Dice: 0.7766
  Val Loss:   0.2512 | Val Dice:   0.7488
  ‚úÖ New best model! Val Dice: 0.7488 (saved)

...

Epoch 100/100 - 142.8s - LR: 0.000008
  Train Loss: 0.2134 | Train Dice: 0.7866
  Val Loss:   0.2398 | Val Dice:   0.7602
  ‚úÖ New best model! Val Dice: 0.7602 (saved)

============================================================
‚úÖ TRAINING COMPLETED!
============================================================
Total training time: 8.2 hours
Best validation Dice: 0.7602 at epoch 95  (+0.06 vs baseline)
```

### 4.2 Auto-Evaluation

Training ‡∏à‡∏∞ run evaluation ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à:

```
============================================================
üß™ RUNNING AUTOMATIC TEST EVALUATION
============================================================

üìä Evaluating on 48 test samples...
üîÑ TTA enabled: ['hflip', 'vflip']
‚úÖ CCA enabled: min_size=10px, min_conf=0.3

Evaluating (TTA+CCA): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48

üìä TEST SET RESULTS:
   Dice:      0.6823 ¬± 0.1123  (+0.06 vs baseline)
   IoU:       0.5523 ¬± 0.1034
   Precision: 0.7423 ¬± 0.1234
   Recall:    0.6523 ¬± 0.1145

‚úÖ TEST EVALUATION COMPLETED!
```

---

## üìä **‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 5: ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå**

### 5.1 ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Training Curves

```bash
# ‡∏î‡∏π training curves
open 4_results/plots/training_curves_separated.png

# ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ MLflow UI
mlflow ui --backend-store-uri mlruns
# ‡πÄ‡∏õ‡∏¥‡∏î browser: http://localhost:5000
```

### 5.2 ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Metrics

```python
# ‡∏™‡∏£‡πâ‡∏≤‡∏á comparison script
python -c "
import pandas as pd
import json

# Load baseline results (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
baseline = pd.read_csv('4_results/baseline_results.csv')

# Load new results
new = pd.read_csv('4_results/test_per_sample_results.csv')

print('='*60)
print('COMPARISON: Baseline vs N4+TTA+CCA')
print('='*60)
print(f'Baseline Dice: {baseline['dice'].mean():.4f}')
print(f'New Dice:      {new['dice'].mean():.4f}')
print(f'Improvement:   +{(new['dice'].mean() - baseline['dice'].mean()):.4f}')
print('='*60)
"
```

---

## üîß **Troubleshooting**

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: SimpleITK ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ

```bash
# ‡∏•‡∏≠‡∏á install ‡∏î‡πâ‡∏ß‡∏¢ conda ‡πÅ‡∏ó‡∏ô pip
conda install -c simpleitk simpleitk

# ‡∏´‡∏£‡∏∑‡∏≠ install version ‡πÄ‡∏â‡∏û‡∏≤‡∏∞
pip install SimpleITK==2.2.1
```

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Out of Memory ‡∏ï‡∏≠‡∏ô Training

```python
# ‡πÅ‡∏Å‡πâ‡πÉ‡∏ô config.py
BATCH_SIZE = 8  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 16
USE_MIXED_PRECISION = True  # ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡∏¥‡∏î
```

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: N4 Correction ‡∏ä‡πâ‡∏≤‡∏°‡∏≤‡∏Å

```python
# ‡πÅ‡∏Å‡πâ‡πÉ‡∏ô config.py
N4_SHRINK_FACTOR = 8  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 4 (‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô 2x ‡πÅ‡∏ï‡πà‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢)
N4_NUM_ITERATIONS = 25  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 50
N4_NUM_WORKERS = 8  # ‡πÄ‡∏û‡∏¥‡πà‡∏° workers (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ CPU ‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏≠‡∏£‡πå)
```

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: TTA ‡∏ä‡πâ‡∏≤‡∏°‡∏≤‡∏Å

```python
# ‡πÅ‡∏Å‡πâ‡πÉ‡∏ô config.py
TTA_AUGMENTATIONS = ['hflip']  # ‡πÉ‡∏ä‡πâ‡πÅ‡∏Ñ‡πà hflip (‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô 2x)
# ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏¥‡∏î TTA
USE_TTA = False
```

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: CCA ‡∏Å‡∏£‡∏≠‡∏á‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ

```python
# ‡πÅ‡∏Å‡πâ‡πÉ‡∏ô config.py
CCA_MIN_SIZE = 5  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 10 (‡∏£‡∏±‡∏Å‡∏©‡∏≤ small lesions ‡πÑ‡∏ß‡πâ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô)
CCA_MIN_CONFIDENCE = 0.2  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 0.3
```

---

## üìà **Expected Results Timeline**

### ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 1-2: TTA + CCA (‡πÑ‡∏°‡πà retrain)
```
Test Dice: 62% ‚Üí 64-66%  (+2-4%)
```

### ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 3-5: N4 + Retrain
```
Val Dice:  70% ‚Üí 73-76%  (+3-6%)
Test Dice: 62% ‚Üí 67-72%  (+5-10%)
```

### ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 6-10: Phase 3-4 (Gamma + Log-Cosh + Deep Supervision)
```
Val Dice:  70% ‚Üí 75-78%  (+5-8%)
Test Dice: 62% ‚Üí 71-79%  (+9-17%)
```

---

## ‚úÖ **Checklist**

### Phase 1-2 (‡∏ó‡∏≥‡πÅ‡∏•‡πâ‡∏ß)
- [x] Install SimpleITK
- [x] ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö TTA/CCA config
- [x] Run evaluate.py ‡∏î‡πâ‡∏ß‡∏¢ TTA+CCA
- [x] Backup ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°
- [x] Run preprocessing ‡∏î‡πâ‡∏ß‡∏¢ N4
- [ ] **Retrain model** ‚Üê ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
- [ ] ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå

### Phase 3-4 (‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ó‡∏≥)
- [ ] ‡πÄ‡∏û‡∏¥‡πà‡∏° Gamma Correction
- [ ] ‡πÄ‡∏û‡∏¥‡πà‡∏° Log-Cosh Dice Loss
- [ ] Retrain ‡∏î‡πâ‡∏ß‡∏¢ augmentation ‡πÉ‡∏´‡∏°‡πà
- [ ] ‡πÄ‡∏û‡∏¥‡πà‡∏° Deep Supervision
- [ ] Final retrain
- [ ] Final evaluation

---

## üìû **Next Steps**

1. **‡∏ó‡∏î‡∏™‡∏≠‡∏ö TTA+CCA:**
   ```bash
   python evaluate.py
   ```

2. **Re-preprocess ‡∏î‡πâ‡∏ß‡∏¢ N4:**
   ```bash
   pip install SimpleITK
   mv 2_data_processed 2_data_processed_backup
   python 01_preprocess.py
   ```

3. **Retrain Model:**
   ```bash
   python train.py
   ```

4. **‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**
   ```bash
   mlflow ui
   # Check metrics in browser
   ```

---

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** ‡∏ó‡∏∏‡∏Å‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ rollback ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ backup ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ß‡πâ

**‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°:** ‡∏î‡∏π‡∏ó‡∏µ‡πà `IMPROVEMENT_PLAN.md` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ
