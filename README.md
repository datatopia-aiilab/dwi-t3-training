# DWI Ischemic Stroke Segmentation Project

## ğŸ¯ Project Overview

This project implements a **2.5D Attention U-Net** for segmenting ischemic stroke lesions from DWI (Diffusion Weighted Imaging) brain scans. The goal is to achieve **Dice Score > 95%** by addressing the challenge of detecting faint lesions.

### Key Features:
- âœ… **2.5D Input**: Uses 3 consecutive slices (N-1, N, N+1) for 3D context
- âœ… **CLAHE Enhancement**: Enhances faint lesion visibility
- âœ… **Attention U-Net**: Focuses on relevant regions
- âœ… **Combo Loss**: Focal Loss + Dice Loss for handling imbalance and hard examples

---

## ğŸ“ Project Structure

```
NovEdition/
â”œâ”€â”€ config.py                      # Configuration (paths, hyperparameters)
â”œâ”€â”€ utils.py                       # Helper functions (metrics, visualization)
â”œâ”€â”€ loss.py                        # Loss functions (Focal, Dice, Combo)
â”œâ”€â”€ model.py                       # Attention U-Net architecture
â”œâ”€â”€ dataset.py                     # PyTorch Dataset (2.5D loading)
â”œâ”€â”€ 01_preprocess.py              # Data preprocessing pipeline
â”œâ”€â”€ train.py                      # Training script (TO BE CREATED)
â”œâ”€â”€ evaluate.py                   # Evaluation script (TO BE CREATED)
â”œâ”€â”€ test_pipeline.py              # Complete pipeline testing
â”œâ”€â”€ requirements.txt              # Python dependencies
â”‚
â”œâ”€â”€ 1_data_raw/                   # Raw data (YOU NEED TO ADD THIS)
â”‚   â”œâ”€â”€ images/                   # Original DWI images
â”‚   â””â”€â”€ masks/                    # Ground truth masks
â”‚
â”œâ”€â”€ 2_data_processed/             # Processed data (auto-generated)
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ test/
â”‚
â”œâ”€â”€ 3_model_weights/              # Saved models (auto-generated)
â””â”€â”€ 4_results/                    # Results and visualizations (auto-generated)
    â”œâ”€â”€ plots/
    â””â”€â”€ predictions/
```

---

## ğŸš€ Quick Start

### Step 1: Install Dependencies

```bash
pip install -r requirements.txt
```

**Required packages:**
- PyTorch >= 2.0.0
- numpy, opencv-python, scikit-image
- albumentations (for augmentation)
- matplotlib, seaborn (for visualization)
- tqdm (for progress bars)

### Step 2: Prepare Your Data

Organize your data following this structure:

```
1_data_raw/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ Patient_001_Slice_001.npy  (or .nii.gz, .png)
â”‚   â”œâ”€â”€ Patient_001_Slice_002.npy
â”‚   â”œâ”€â”€ Patient_001_Slice_015.npy
â”‚   â”œâ”€â”€ Patient_002_Slice_001.npy
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ masks/
    â”œâ”€â”€ Patient_001_Slice_001.npy  (same name as images!)
    â”œâ”€â”€ Patient_001_Slice_002.npy
    â”œâ”€â”€ Patient_001_Slice_015.npy
    â”œâ”€â”€ Patient_002_Slice_001.npy
    â””â”€â”€ ...
```

**Important Rules:**
- âœ… File names MUST match between images and masks
- âœ… Use format: `Patient_{XXX}_Slice_{YYY}.ext`
- âœ… Use zero-padding (001, 002, not 1, 2)
- âœ… Slice numbers should be consecutive within each patient

### Step 3: Test the Pipeline (RECOMMENDED)

Before using real data, test the pipeline with dummy data:

```bash
python test_pipeline.py
```

This will:
1. Create dummy data
2. Test all components
3. Run a mini training loop
4. Verify everything works

### Step 4: Run Preprocessing

```bash
python 01_preprocess.py
```

This will:
- Split data into train/val/test (70/15/15)
- Apply CLAHE enhancement
- Normalize images (Z-score)
- Save processed .npy files

### Step 5: Train the Model

```bash
python train.py
```

(Note: train.py needs to be created - see TODO section)

### Step 6: Evaluate Results

```bash
python evaluate.py
```

(Note: evaluate.py needs to be created - see TODO section)

---

## âœ… Pre-Flight Checklist

### Before Running Preprocessing:

- [ ] âœ… Dependencies installed (`pip install -r requirements.txt`)
- [ ] âœ… Data organized in `1_data_raw/images/` and `1_data_raw/masks/`
- [ ] âœ… File names follow pattern: `Patient_XXX_Slice_YYY.ext`
- [ ] âœ… Image and mask files have matching names
- [ ] âœ… Tested with `python test_pipeline.py` (HIGHLY RECOMMENDED)
- [ ] âœ… Reviewed `config.py` settings (image size, CLAHE params, etc.)

### After Preprocessing:

- [ ] âœ… Check `2_data_processed/` folders are populated
- [ ] âœ… Verify train/val/test splits look reasonable
- [ ] âœ… Review `normalization_stats.json` (mean/std values)
- [ ] âœ… Inspect a few processed images visually

### During Training:

- [ ] âœ… Monitor training/validation loss curves
- [ ] âœ… Check Dice score improvements
- [ ] âœ… Watch for overfitting (val loss increasing)
- [ ] âœ… Verify GPU utilization (use `nvidia-smi`)

### After Training:

- [ ] âœ… Best model saved in `3_model_weights/`
- [ ] âœ… Training curves plotted in `4_results/plots/`
- [ ] âœ… Qualitative results generated (predictions overlaid)
- [ ] âœ… Test set metrics computed (Dice, IoU, Precision, Recall)

---

## ğŸ”§ Configuration

Edit `config.py` to customize:

### Data Parameters:
- `IMAGE_SIZE`: Target size for all images (default: 256Ã—256)
- `TRAIN_RATIO`, `VAL_RATIO`, `TEST_RATIO`: Data split ratios
- `MIN_SLICES_PER_PATIENT`: Minimum slices to include a patient

### CLAHE Parameters:
- `CLAHE_ENABLED`: Enable/disable CLAHE (default: True)
- `CLAHE_CLIP_LIMIT`: Clipping limit (0.01-0.05, default: 0.03)

### Model Parameters:
- `IN_CHANNELS`: Input channels (3 for 2.5D)
- `ENCODER_CHANNELS`: Encoder layer sizes (default: [64, 128, 256, 512])
- `USE_ATTENTION`: Enable/disable attention gates (default: True)

### Training Parameters:
- `NUM_EPOCHS`: Training epochs (default: 100)
- `BATCH_SIZE`: Batch size (default: 8)
- `LEARNING_RATE`: Initial learning rate (default: 1e-4)
- `LOSS_TYPE`: Loss function ('focal', 'dice', or 'combo')

### Augmentation Parameters:
- `AUGMENTATION_ENABLED`: Enable/disable augmentation
- `AUG_HORIZONTAL_FLIP_PROB`: Probability of horizontal flip
- `AUG_ELASTIC_TRANSFORM_PROB`: Probability of elastic transform (IMPORTANT!)

---

## ğŸ“Š Expected Results

### Target Metrics:
- **Dice Score**: > 95%
- **IoU**: > 90%
- **Precision & Recall**: Balanced

### Comparison:
- **Baseline U-Net**: ~75% Dice (misses faint lesions)
- **Our Approach**: > 95% Dice (captures both bright and faint lesions)

---

## ğŸ§ª Testing

### Test Individual Components:

```bash
# Test utilities
python utils.py

# Test loss functions
python loss.py

# Test model architecture
python model.py

# Test dataset loading
python dataset.py

# Test complete pipeline
python test_pipeline.py
```

Each module has built-in tests at the bottom of the file.

---

## ğŸ› Troubleshooting

### Issue: "Import errors" when running scripts
**Solution**: Install dependencies: `pip install -r requirements.txt`

### Issue: "No files found" during preprocessing
**Solution**: Check file naming pattern matches `Patient_XXX_Slice_YYY`

### Issue: "Out of memory" during training
**Solution**: Reduce `BATCH_SIZE` in `config.py`

### Issue: "Model not improving"
**Solution**: 
- Check if CLAHE is enabled
- Verify data augmentation is working
- Try different loss weights in Combo Loss
- Check learning rate (may need adjustment)

### Issue: "Validation loss increasing (overfitting)"
**Solution**:
- Enable more augmentation
- Increase dropout
- Use early stopping (already implemented)

---

## ğŸ“ TODO List

### Core Scripts (High Priority):
- [ ] **train.py** - Training pipeline with:
  - Training loop
  - Validation
  - Checkpointing
  - Early stopping
  - Logging
  
- [ ] **evaluate.py** - Evaluation script with:
  - Test set evaluation
  - Metrics calculation
  - Training curves plotting
  - Qualitative visualizations

### Enhancements (Medium Priority):
- [ ] Add mixed precision training (for speed)
- [ ] Add TensorBoard logging
- [ ] Add Weights & Biases integration
- [ ] Add model ensemble
- [ ] Add post-processing (morphological operations)

### Advanced Features (Low Priority):
- [ ] Add cross-validation
- [ ] Add hyperparameter tuning
- [ ] Add model interpretation (attention maps visualization)
- [ ] Add uncertainty estimation
- [ ] Add 3D volumetric evaluation

---

## ğŸ“š References

### Papers:
1. **Attention U-Net**: Oktay et al., "Attention U-Net: Learning Where to Look for the Pancreas" (2018)
2. **Focal Loss**: Lin et al., "Focal Loss for Dense Object Detection" (2017)
3. **U-Net**: Ronneberger et al., "U-Net: Convolutional Networks for Biomedical Image Segmentation" (2015)

### Libraries:
- PyTorch: https://pytorch.org/
- Albumentations: https://albumentations.ai/
- scikit-image: https://scikit-image.org/

---

## ğŸ‘¥ Contributors

- **Your Name** - Initial implementation

---

## ğŸ“„ License

[Add your license here]

---

## ğŸ‰ Acknowledgments

This project implements a 4-core integrated strategy for improving stroke lesion segmentation:
1. **2.5D Input** - 3D context
2. **CLAHE** - Contrast enhancement
3. **Attention U-Net** - Focused learning
4. **Combo Loss** - Robust optimization

Good luck with your research! ğŸš€
